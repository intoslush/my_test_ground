{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchmetrics tensorboard \n",
    "# %pip uninstall clip\n",
    "# %pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from balanced_batch_sampler import BalancedBatchSampler\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "# from torch.utils.data import Dataset\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "SAVE_INTERVAL = 10\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "\n",
    "def convert_models_to_fp32(model):\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.float()\n",
    "        if p.requires_grad:\n",
    "            p.grad.data = p.grad.data.float()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)  #Must set jit=False for training\n",
    "if device == \"cpu\":\n",
    "    model.float()\n",
    "else:\n",
    "    clip.model.convert_weights(model)  # Actually this line is unnecessary since clip by default already on float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimitedImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None, limit_per_class=4):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.limit_per_class = limit_per_class\n",
    "        self.samples = self._gather_samples()\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "\n",
    "    def _gather_samples(self):\n",
    "        samples = []\n",
    "        class_counts = defaultdict(int)  # 初始化类别计数字典\n",
    "\n",
    "        # 遍历每个数据集文件夹\n",
    "        for dataset_dir in os.listdir(self.root):\n",
    "            dataset_path = os.path.join(self.root, dataset_dir)\n",
    "            if not os.path.isdir(dataset_path):\n",
    "                continue\n",
    "\n",
    "            # 遍历每个类别文件夹\n",
    "            for class_dir in os.listdir(dataset_path):\n",
    "                class_path = os.path.join(dataset_path, class_dir)\n",
    "                if not os.path.isdir(class_path):\n",
    "                    continue\n",
    "\n",
    "                # 获取类别内的所有图像路径\n",
    "                class_images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "                \n",
    "                # 随机选择limit_per_class张图像\n",
    "                selected_images = random.sample(class_images, min(self.limit_per_class, len(class_images)))\n",
    "                for img_path in selected_images:\n",
    "                    class_idx = class_dir\n",
    "                    samples.append((img_path, class_idx))\n",
    "                    class_counts[class_idx] += 1  # 更新类别计数\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(\"len是\",len(self.samples))\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=LimitedImageFolder(\"data/TrainSet\", transform=preprocess,limit_per_class=4)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,drop_last=False,shuffle=True,num_workers=4,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     images, class_ids = batch\n",
    "#     for label_id in class_ids:\n",
    "#         print(type(class_ids))\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=LimitedImageFolder(\"data/TrainSet\", transform=preprocess,limit_per_class=8)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,drop_last=True,shuffle=True,num_workers=4,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_img = torch.nn.CrossEntropyLoss()\n",
    "loss_txt = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# for p in model.transformer.parameters():\n",
    "#     p.requires_grad = False\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(\n",
    "    params, lr=1e-7, weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches_train = len(train_dataloader.dataset)/BATCH_SIZE\n",
    "writer = SummaryWriter()\n",
    "weights_path = Path(\"model_checkpoints\")\n",
    "weights_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_class_name_dic()->dict:\n",
    "    \"\"\"返回动物名字到数字的字典\"\"\"\n",
    "    classes = open('data/classname.txt').read().splitlines()#这是一个包含所有类的列表\n",
    "    class_name_dic={}#这是数字映射到动物名字的字典\n",
    "    for i in classes:\n",
    "        name,idx = i.split(' ')\n",
    "        c = name\n",
    "        if c.startswith('Animal'):\n",
    "            c = c[7:]\n",
    "        if c.startswith('Thu-dog'):\n",
    "            c = c[8:]\n",
    "        if c.startswith('Caltech-101'):\n",
    "            c = c[12:]\n",
    "        if c.startswith('Food-101'):\n",
    "            c = c[9:]\n",
    "        if c not in class_name_dic:\n",
    "            class_name_dic[c]=idx\n",
    "        else:\n",
    "            print(name,\"already exist!!\")\n",
    "    return class_name_dic\n",
    "class_dic=ret_class_name_dic()\n",
    "class_list=list(class_dic.keys())\n",
    "# class_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187.0 [00:24<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights under model_checkpoint/model_0.pt.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    epoch_train_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader,total=num_batches_train):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, class_ids = batch\n",
    "\n",
    "        images = torch.stack([img for img in images], dim=0).to(\n",
    "            device\n",
    "        )\n",
    "        # TODO: to use mean of multiple prompts need to pre-compute them.\n",
    "        texts = [f\"a photo of a {label_id}\" for label_id in class_ids]\n",
    "        texts = clip.tokenize(texts).to(device)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "\n",
    "        ground_truth = torch.arange(logits_per_image.shape[0], dtype=torch.long, device=device)\n",
    "        # print(\"#####logits_per_image.shape[0]是\",logits_per_image.shape[0])\n",
    "        # print(ground_truth,\"#####ground_truth.shape是\",logits_per_image.shape)\n",
    "        total_train_loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "        total_train_loss.backward()\n",
    "        epoch_train_loss += total_train_loss\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(params, 1.0)\n",
    "\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            clip.model.convert_weights(model)\n",
    "        \n",
    "\n",
    "    epoch_train_loss /= num_batches_train\n",
    "    writer.add_scalar(\"Loss/train\", epoch_train_loss, epoch)\n",
    "\n",
    "    if epoch== 0 % 8 or epoch==2 or epoch==5:\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_train_loss,\n",
    "            }, weights_path / f\"model_{epoch}.pt\")  #just change to your preferred folder/filename\n",
    "        print(f\"Saved weights under model_checkpoint/model_{epoch}.pt.\")\n",
    "\n",
    "    # Compute test accuracy\n",
    "    # model.eval()\n",
    "    # values_list, indices_list = [], []\n",
    "    # top5_results = []\n",
    "    # top1_results = []\n",
    "    # acc_top1_list = []\n",
    "    # acc_top5_list = []\n",
    "\n",
    "    # num_batches_test = len(test_dataloader.dataset)/BATCH_SIZE\n",
    "    # epoch_test_loss = 0\n",
    "    # for i, batch in enumerate(tqdm(test_dataloader, total=num_batches_test)):\n",
    "    #     images, class_ids = batch\n",
    "    #     # class_ids = class_ids.to(device)\n",
    "\n",
    "    #     images = images.to(device)\n",
    "    #     texts = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in class_list]).to(device)\n",
    "    #     text2 = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in class_ids]).to(device)\n",
    "    #     with torch.no_grad():\n",
    "    #         # TODO: remove duplicate computation of image and text features\n",
    "    #         image_features = model.encode_image(images)\n",
    "    #         text_features = model.encode_text(text2)\n",
    "\n",
    "    #         logits_per_image, logits_per_text = model(images, text2)\n",
    "    #         ground_truth = torch.arange(logits_per_image.shape[0], dtype=torch.long, device=device)\n",
    "    #         total_loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "    #         epoch_test_loss += total_loss\n",
    "\n",
    "    # text_features = model.encode_text(texts)\n",
    "    # image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    # text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    # similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1).to(device)\n",
    "    # true_label=torch.tensor([int(class_dic[i]) for i in class_ids]).to(device)\n",
    "    # # print(\"此处true_label.shape为\",true_label.shape)\n",
    "    # # print(\"此处similarit.shape为\",similarity.shape)\n",
    "    # acc_top1 = torchmetrics.functional.accuracy(similarity,true_label,top_k=1,task=\"multiclass\",num_classes=len(class_list))\n",
    "    # acc_top5 = torchmetrics.functional.accuracy(similarity, true_label, top_k=5,task=\"multiclass\",num_classes=len(class_list))\n",
    "    # acc_top1_list.append(acc_top1)\n",
    "    # acc_top5_list.append(acc_top5)\n",
    "    # writer.add_scalar(\"Loss/test\", epoch_test_loss / num_batches_test, epoch)\n",
    "\n",
    "    # print(f\"Epoch {epoch} train loss: {epoch_train_loss / num_batches_train}\")\n",
    "    # print(f\"Epoch {epoch} test loss: {epoch_test_loss / num_batches_test}\")\n",
    "\n",
    "    # # compute mean top5 accuracy and top1 accuracy\n",
    "    # mean_top5_accuracy = torch.stack(acc_top5_list).mean().cpu().numpy()\n",
    "    # print(f\"Mean Top 5 Accuracy: {mean_top5_accuracy*100}%.\")\n",
    "    # writer.add_scalar(\"Test Accuracy/Top5\", mean_top5_accuracy , epoch)\n",
    "    # mean_top1_accuracy = torch.stack(acc_top1_list).mean().cpu().numpy()\n",
    "    # print(f\"Mean Top 1 Accuracy: {mean_top1_accuracy*100}%.\")\n",
    "    # writer.add_scalar(\"Test Accuracy/Top1\", mean_top1_accuracy, epoch)\n",
    "    # torch.cuda.empty_cache()\n",
    "    # if epoch==0:\n",
    "    #     break\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = open('data/classname.txt').read().splitlines()\n",
    "model.eval()\n",
    "# 冻结所有模型参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# remove the prefix Animal, Thu-dog, Caltech-101, Food-101\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "new_classes = []\n",
    "for c in classes:\n",
    "    c = c.split(' ')[0]\n",
    "    if c.startswith('Animal'):\n",
    "        c = c[7:]\n",
    "    if c.startswith('Thu-dog'):\n",
    "        c = c[8:]\n",
    "    if c.startswith('Caltech-101'):\n",
    "        c = c[12:]\n",
    "    if c.startswith('Food-101'):\n",
    "        c = c[9:]\n",
    "    c = 'a photo of ' + c\n",
    "    new_classes.append(c)\n",
    "\n",
    "text = clip.tokenize(new_classes).to(device)\n",
    "text_features = model.encode_text(text)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "split = 'TestSetA' \n",
    "\n",
    "imgs_dir = 'data/' + split\n",
    "imgs = os.listdir(imgs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3073/3073 [07:11<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_file = open('result.txt', 'w')\n",
    "\n",
    "preds = []\n",
    "model.eval()\n",
    "count=0\n",
    "for img in tqdm(imgs):\n",
    "    img_path = os.path.join(imgs_dir, img)\n",
    "    image = Image.open(img_path)\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "    image_features = model.encode_image(image)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_probs = (100.0 *\n",
    "                    image_features @ text_features.transpose(0, 1)).softmax(\n",
    "                        dim=-1)\n",
    "    # top5 predictions\n",
    "    _, top_labels = text_probs[0].topk(5)\n",
    "    preds.append(top_labels)\n",
    "    # save top5 predictions to file\n",
    "    save_file.write(img + ' ' +\n",
    "                    ' '.join([str(p.item()) for p in top_labels]) + '\\n')\n",
    "    del image,_, top_labels,image_features,img_path,text_probs\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    count+=1\n",
    "print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
