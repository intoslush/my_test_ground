{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from back_save.为了测试clip的原始算法.balanced_batch_sampler import BalancedBatchSampler\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=10\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "if device == \"cpu\":\n",
    "  model.float()\n",
    "else :\n",
    "  clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n",
    "def convert_models_to_fp32(model): \n",
    "    \"\"\"这个一定要有,不然梯度直接爆炸\"\"\"\n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "class image_title_dataset(Dataset):\n",
    "    def __init__(self, list_image_path,list_txt,nidx,need_path:bool=False):\n",
    "\n",
    "        self.image_path = list_image_path\n",
    "        self.mark=False\n",
    "        if len(list_txt)>1:\n",
    "            self.mark=True\n",
    "            self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
    "        else:\n",
    "            self.title=False\n",
    "        # self.title=self.title\n",
    "        self.nidx=nidx\n",
    "        self.npath=need_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = preprocess(Image.open(self.image_path[idx])) # Image from PIL module\n",
    "        if self.mark ==False:\n",
    "            title=\"-1\"\n",
    "        else:\n",
    "            title = self.title[idx]\n",
    "        \n",
    "        if self.npath:\n",
    "            ndix=os.path.basename(self.image_path[idx])\n",
    "        else:\n",
    "            ndix=self.nidx[idx]\n",
    "        return image,title,ndix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_class_name_dic()->dict:\n",
    "    \"\"\"返回动物名字到数字和数字映射到动物名的字典\"\"\"\n",
    "    classes = open('data/classname.txt').read().splitlines()#这是一个包含所有类的列表\n",
    "    class_name_dic_num={}\n",
    "    class_name_dic_name={}\n",
    "    for i in classes:\n",
    "        name,idx = i.split(' ')\n",
    "        c = name\n",
    "        if c.startswith('Animal'):\n",
    "            c = c[7:]\n",
    "        if c.startswith('Thu-dog'):\n",
    "            c = c[8:]\n",
    "        if c.startswith('Caltech-101'):\n",
    "            c = c[12:]\n",
    "        if c.startswith('Food-101'):\n",
    "            c = c[9:]\n",
    "        if c not in class_name_dic_name:\n",
    "            class_name_dic_name[c]=idx\n",
    "            class_name_dic_num[idx]=c\n",
    "        else:\n",
    "            print(name,\"already exist!!\")\n",
    "    return class_name_dic_name,class_name_dic_num\n",
    "class_name_dic_name,class_name_dic_num=ret_class_name_dic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_pic_patch(num_pic=4)->dict:\n",
    "    \"\"\"返回每类四张,的路径和标签\"\"\"\n",
    "    # num_pic=8#返回的图片数量\n",
    "    r_path=[]\n",
    "    r_class_num=[]\n",
    "    info = open('data/train.txt').read().splitlines()\n",
    "    \n",
    "    class_check=0\n",
    "    temp_path=[]\n",
    "    temp_class=[]\n",
    "    for i in info:\n",
    "        path,class_num=i.split(' ')\n",
    "        path=\"data/\"+path\n",
    "        if class_check==int(class_num):\n",
    "            temp_path.append(path)\n",
    "            temp_class.append(class_num)\n",
    "        else:\n",
    "            class_check=int(class_num)\n",
    "\n",
    "            r_path+=random.sample(temp_path,min(num_pic,len(temp_path)))\n",
    "            r_class_num+=random.sample(temp_class,min(num_pic,len(temp_path)))\n",
    "            temp_path=[path]\n",
    "            temp_class=[class_num]\n",
    "    r_path+=random.sample(temp_path,min(num_pic,len(temp_path)))\n",
    "    r_class_num+=random.sample(temp_class,min(num_pic,len(temp_path)))\n",
    "    return r_path,r_class_num\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_test_pic_patch(num_pic=3000,list_image_path1=[]):\n",
    "    \"\"\"返回测试集的路径和标签,注意这里的数量是种数量\"\"\"\n",
    "    # num_pic=8#返回的图片数量\n",
    "    r_path=[]\n",
    "    r_class_num=[]\n",
    "    info = open('data/train.txt').read().splitlines()\n",
    "    random.shuffle(info)\n",
    "    count=0\n",
    "    set_train=set(list_image_path1)\n",
    "    for i in info:\n",
    "        path,class_num=i.split(' ')\n",
    "        path=\"data/\"+path\n",
    "        if i in set_train:\n",
    "            continue\n",
    "        else:\n",
    "            r_path.append(path)\n",
    "            r_class_num.append(class_num)\n",
    "            count+=1\n",
    "            if count==num_pic:\n",
    "                break\n",
    "    return r_path,r_class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集和测试集数据准备\n",
    "list_image_path1,class_num1=ret_pic_patch(num_pic=4)#训练集每类四个\n",
    "list_image_path2,class_num2=ret_test_pic_patch(num_pic=3000,list_image_path1=list_image_path1)#共计3000张图片\n",
    "print(\"len(list_image_path2)\",len(list_image_path2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list_image_path1,list_image_path2=np.array_split(list_image_path, 2)\n",
    "# class_num1,class_num2=np.array_split(class_num, 2)\n",
    "\n",
    "list_txt1 =[\"a photo of a \"+class_name_dic_num[i] for i in class_num1]\n",
    "dataset = image_title_dataset(list_image_path1,list_txt1,class_num1)\n",
    "train_dataloader = DataLoader(dataset,batch_size = BATCH_SIZE,shuffle=True)\n",
    "\n",
    "# 测试集的数据\n",
    "\n",
    "list_txt2=[\"a photo of a \"+class_name_dic_num[i] for i in class_num2]\n",
    "test_dataset= image_title_dataset(list_image_path2,list_txt2,class_num2)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size = BATCH_SIZE,shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备loss函数和优化器\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "# for p in model.transformer.parameters():\n",
    "#   p.requires_grad = True\n",
    "# 解冻视觉模型最后两个残差块的参数\n",
    "for param in model.visual.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.visual.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻文本模型最后两个残差块的参数\n",
    "for param in model.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻 ln_final 层的参数\n",
    "for param in model.ln_final.parameters():\n",
    "    param.requires_grad = True\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=1e-5, weight_decay=0.0001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符编码每一类\n",
    "classes = open('data/classname.txt').read().splitlines()\n",
    "new_classes = []\n",
    "for c in classes:\n",
    "    c = c.split(' ')[0]\n",
    "    if c.startswith('Animal'):\n",
    "        c = c[7:]\n",
    "    if c.startswith('Thu-dog'):\n",
    "        c = c[8:]\n",
    "    if c.startswith('Caltech-101'):\n",
    "        c = c[12:]\n",
    "    if c.startswith('Food-101'):\n",
    "        c = c[9:]\n",
    "    c = 'a photo of ' + c\n",
    "    new_classes.append(c)\n",
    "print(new_classes[0:5])\n",
    "text2 = clip.tokenize(new_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print(\"epoch______________________________\",epoch)\n",
    "    total_count=0\n",
    "    total_count1=0\n",
    "    total_count5=0\n",
    "    count_loss=0\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images,texts,idx = batch \n",
    "        images= images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        # images = torch.stack([img for img in images], dim=0).to(device)\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "        # print(\"loss为\",total_loss)\n",
    "        count_loss+=total_loss\n",
    "        total_loss.backward()\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else : \n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            clip.model.convert_weights(model)\n",
    "        # break \n",
    "    # break  \n",
    "    print('训练loss为',count_loss)\n",
    "    \n",
    "    # if not epoch%3==0:\n",
    "    #     continue\n",
    "    model.eval()\n",
    "    for batch in test_dataloader :\n",
    "        images,texts,idx = batch \n",
    "        images= images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        logits_per_image, logits_per_text =model(images, text2)\n",
    "        text_probs=logits_per_image.softmax(dim=-1)\n",
    "        for i in range(len(idx)):\n",
    "            top5=text_probs[i].topk(5).indices.tolist()\n",
    "            if int(idx[i]) in top5:\n",
    "                total_count5+=1\n",
    "                if int(idx[i])==top5[0]:\n",
    "                    total_count1+=1      \n",
    "        total_count+=len(idx)\n",
    "      \n",
    "\n",
    "    print(f\"测试集准确率 Top-1: {total_count1 / total_count:.4f}, \"\n",
    "      f\"测试集准确率 Top-5: {total_count5 / total_count:.4f}, \"\n",
    "      f\"Top-1 正确个数: {total_count1}, \"\n",
    "      f\"Top-5 正确个数: {total_count5}, \"\n",
    "      f\"总数: {total_count}\")\n",
    "    acc=total_count1 / total_count\n",
    "    if acc>best_acc:\n",
    "        best_acc=acc\n",
    "        torch.save({\n",
    "            'acc': total_count1 / total_count,\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': total_loss,\n",
    "            }, f\"model_checkpoint/model_best_acc.pt\") #just change to your preferred folder/filename\n",
    "        \n",
    "    # del count_loss,total_count1,total_count,total_count5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#         'epoch': epoch,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'loss': total_loss,\n",
    "#         }, f\"model_checkpoint/model_10.pt\") #just change to your preferred folder/filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载之前训练的模型\n",
    "# model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "checkpoint = torch.load(\"model_checkpoint/model_best_acc.pt\")\n",
    "\n",
    "# # Use these 3 lines if you use default model setting(not training setting) of the clip. For example, if you set context_length to 100 since your string is very long during training, then assign 100 to checkpoint['model_state_dict'][\"context_length\"] \n",
    "# checkpoint['model_state_dict'][\"input_resolution\"] = model.input_resolution #default is 224\n",
    "# checkpoint['model_state_dict'][\"context_length\"] = model.context_length # default is 77\n",
    "print(\"测试集的准确率为\",checkpoint[\"acc\"],\"epoch为\",checkpoint[\"epoch\"])\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提交的数据集\n",
    "imgs_dir = 'data/' + 'TestSetA/' \n",
    "save_path='data/result.txt'\n",
    "imgs = os.listdir(imgs_dir)\n",
    "save_file = open(save_path, 'w')\n",
    "file_paths = [os.path.join(imgs_dir, file_name) for file_name in imgs]\n",
    "\n",
    "test_dataset= image_title_dataset(file_paths,[],[],True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size = BATCH_SIZE,shuffle=True)\n",
    "model.eval()\n",
    "count=0\n",
    "for batch in tqdm(test_dataloader) :\n",
    "    images,_,file_name = batch \n",
    "    images= images.to(device)\n",
    "    logits_per_image, logits_per_text =model(images, text2)\n",
    "    text_probs=logits_per_image.softmax(dim=-1)\n",
    "    \n",
    "    for i in range(len(file_name)):\n",
    "        if len(text_probs[i])>=5:\n",
    "            top5=text_probs[i].topk(5).indices.tolist()\n",
    "    \n",
    "        save_file.write(file_name[i] + ' ' +' '.join([str(p) for p in top5]) + '\\n')  \n",
    "        count+=1\n",
    "        # print(file_name[i] + ' ' +' '.join([str(p) for p in top5]) + '\\n')\n",
    "print(\"写入完成,共计\",count)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# 压缩结果文件\n",
    "zip_file_path = 'data/result.zip'\n",
    "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "    zipf.write(save_path, os.path.basename(save_path))\n",
    "\n",
    "# 删除原文件\n",
    "os.remove(save_path)\n",
    "print(f\"{save_path} 已压缩为 {zip_file_path} 并删除原文件。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
