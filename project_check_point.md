# jittor图片迁移训练比赛
[TOC]
## 第一周目标
1. 使用pytorch完成todo
由于大部分资料,和我目前学习都是使用的pytorch,所以目前计划使用pytorch来完成测试和代码构建,后续再迁移到jittor上
2. 模型原本zero-shot就有73.6%的准确率,为什么我zero-shot只有五十多的准确率,为什么?准确率都丢失到了哪

### TODO
    - 构造本地的测试集
    - 从每个类别随机抽取四张图片
    - 从剩下的图片里面抽3000张图片构成测试集,
    - 构建三个测试集
    - 就使用单层的全连接层+softmax稍微调下看下准确率
    - 分析准确率大概丢失在哪

## 杂项
### baseline相关
1.baseline的原理
不用训练版: 使用clip预训练模型,调用model自带的方法对文本和图片分别求向量,然后做矩阵乘法, 最后套一个softmax出概率.

训练版: 和免训练版一样,求出文本和图片的向量, 不过文本的向量完全没用, 训练也只是把图片处理后的向量直接丢到一个单层的全连接层然后套个softmax,后去与标签的数字去拟合
(其实给的参考代码就是openai给的示例稍微改了点)

### 大的目标
- 替换掉直接简单粗暴的全连接+softmax而直接对原来的模型
- 进行数据增广

## 资料汇总
openai给出的模型的一些api
https://github.com/openai/CLIP

