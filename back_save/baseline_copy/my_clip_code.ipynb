{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from PIL import Image\n",
    "import jclip as clip\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import random\n",
    "# from colorama import Fore, Back, Style, init\n",
    "# init()\n",
    "\n",
    "jt.flags.use_cuda = 1\n",
    "print(\"包导入成功\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--split', type=str, default='A')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "model, preprocess = clip.load(\"../data/ViT-B-32.pkl\")\n",
    "imgs_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode这块后面可以强化下\n",
    "def encode_pre_word(c)->str:\n",
    "    \"\"\"更具输入的名字返回一句话\"\"\"\n",
    "    seq = 'a photo of ' + c\n",
    "    return seq\n",
    "\n",
    "def ret_class_name_dic()->dict:\n",
    "    \"\"\"返回数字映射到动物名字的字典\"\"\"\n",
    "    classes = open('../data/classname.txt').read().splitlines()#这是一个包含所有类的列表\n",
    "    class_name_dic={}#这是数字映射到动物名字的字典\n",
    "    for i in classes:\n",
    "        name,idx = i.split(' ')\n",
    "        if idx not in class_name_dic:\n",
    "            class_name_dic[idx]=name\n",
    "    return class_name_dic\n",
    "\n",
    "# class_name_dic=ret_class_name_dic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练的数据处理\n",
    "def train_data()->list:\n",
    "    \"\"\"返回元素为玩意的列表['TrainSet/Animal/Bee/57.jpg', '1'] 每类四个的打乱列表\"\"\"\n",
    "    train_labels = open('../data/train.txt').read().splitlines()\n",
    "    train_data_dic={}#每类的图片的字典\n",
    "    for i in train_labels:\n",
    "        path,class_name=i.split(' ')\n",
    "        if class_name in train_data_dic:\n",
    "            train_data_dic[class_name].append([path,class_name])\n",
    "        else:\n",
    "            train_data_dic[class_name]=[]\n",
    "    # 训练集的要训练的每类四张的列表\n",
    "    ret_list=[]#用于返回每类四张的列表\n",
    "    for i in train_data_dic:\n",
    "        ret_list+=random.sample(train_data_dic[i],4)\n",
    "    random.shuffle(ret_list)\n",
    "    return ret_list# 内存不够再优化\n",
    "\n",
    "# train_data=train_data()\n",
    "#测试数据列表返回\n",
    "def test_data(train_data:list)->list:\n",
    "    \"\"\"返回元素为玩意的列表['TrainSet/Animal/Bee/57.jpg 1] 共计3000个用于测试\n",
    "    同时剔除训练集中的元素\"\"\"\n",
    "    set1=set(train_data)\n",
    "    train_labels = open('../data/train.txt').read().splitlines()\n",
    "    result = [item for item in train_labels if item not in set1] \n",
    "    return random.sample(result,3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把句子和图片进行encoding\n",
    "train_img_features = []\n",
    "train_word_features=[]\n",
    "count=0\n",
    "with jt.no_grad():\n",
    "    class_name_dic=ret_class_name_dic()\n",
    "    for info in tqdm(train_data()):\n",
    "\n",
    "        img,indx=info\n",
    "        img = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        # print(\"能成功运行?\",\"image_features的shape是\",image_features.shape)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        train_img_features.append(image_features)\n",
    "\n",
    "        a_seq=encode_pre_word(class_name_dic[indx])#转为句子\n",
    "        token=clip.tokenize(a_seq)\n",
    "        \n",
    "        text_features=model.encode_text(token)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        # print(\"text_features的shape为\",text_features.shape)\n",
    "        train_word_features.append(text_features)\n",
    "        count+=1\n",
    "        if count==5 :\n",
    "            break\n",
    "\n",
    "train_features = jt.cat(train_img_features).numpy()#(1496, 512)\n",
    "train_labels = jt.cat(train_word_features).numpy()#(1496,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把原模型的最后一层给改了,然后最后两层微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结所有模型参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 解冻视觉模型最后两个残差块的参数\n",
    "for param in model.visual.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.visual.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻文本模型最后两个残差块的参数\n",
    "for param in model.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻 ln_final 层的参数\n",
    "for param in model.ln_final.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评分函数 s(image, text)\n",
    "def score_function(image_embedding, text_embedding):\n",
    "    # 使用余弦相似度作为评分函数\n",
    "    return jt.matmul(image_embedding, text_embedding.transpose(1, 0))\n",
    "\n",
    "# 定义 CLIP 损失函数\n",
    "def clip_loss(image_embeddings, text_embeddings, temperature=1.0):\n",
    "    batch_size = image_embeddings.shape[0]\n",
    "    \n",
    "    # 计算所有文本描述与图像之间的评分\n",
    "    scores = score_function(image_embeddings, text_embeddings)\n",
    "    \n",
    "    # 计算对比损失函数\n",
    "    logits = scores / temperature\n",
    "    logits_max, _ = jt.max(logits, dim=1, keepdims=True)\n",
    "    logits = logits - logits_max.detach()  # 避免数值不稳定性\n",
    "    exp_logits = jt.exp(logits)\n",
    "    softmax_probs = exp_logits / jt.sum(exp_logits, axis=1, keepdims=True)\n",
    "    # 对角线位置的 softmax 概率即为对应的文本描述与图像匹配的概率\n",
    "    correct_probs = jt.diag(softmax_probs)\n",
    "    # 计算对比损失\n",
    "    loss = -jt.log(correct_probs + 1e-6).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = jt.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
