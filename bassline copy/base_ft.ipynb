{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ftfy regex tqdm\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0616 17:51:08.919792 44 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:08.977551 44 compiler.py:956] Jittor(1.3.8.5) src: /root/miniconda3/envs/pyt/lib/python3.10/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:08.980400 44 compiler.py:957] g++ at /usr/bin/g++(9.4.0)\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:08.980976 44 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.8/g++9.4.0/py3.10.11/Linux-5.4.0-16xb5/IntelRXeonRPlax40/default\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:08.984114 44 __init__.py:411] Found /usr/local/cuda/bin/nvcc(11.7.99) at /usr/local/cuda/bin/nvcc.\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:08.986962 44 __init__.py:411] Found addr2line(2.34) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:09.072711 44 compiler.py:1011] cuda key:cu11.7.99_sm_70\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:09.413049 44 __init__.py:227] Total mem: 38.42GB, using 12 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:09.554507 44 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:09.628894 44 init.cc:62] Found cuda archs: [70,]\u001b[m\n",
      "\u001b[38;5;2m[i 0616 17:51:12.418794 44 cuda_flags.cc:49] CUDA enabled.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包导入成功\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "from PIL import Image\n",
    "import jclip as clip\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import random\n",
    "# from colorama import Fore, Back, Style, init\n",
    "# init()\n",
    "\n",
    "jt.flags.use_cuda = 1\n",
    "print(\"包导入成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--split', type=str, default='A')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "model, preprocess = clip.load(\"ViT-B-32.pkl\")\n",
    "classes = open('../data/classname.txt').read().splitlines()#这是一个包含所有类的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别文本编码,变成一句话,然后别转为向量\n",
    "### 提示词可以尝试优化\n",
    "text_features的shape为[374,512,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 中图片\n",
      "[374,77,]\n",
      "norm前的shape [374,512,]\n",
      "[374,512,]\n",
      "标签处理成功\n"
     ]
    }
   ],
   "source": [
    "# encode这块后面可以强化下\n",
    "text_features=0\n",
    "new_classes = []\n",
    "for c in classes:\n",
    "    c = c.split(' ')[0]\n",
    "    if c.startswith('Animal'):\n",
    "        c = c[7:]\n",
    "    if c.startswith('Thu-dog'):\n",
    "        c = c[8:]\n",
    "    if c.startswith('Caltech-101'):\n",
    "        c = c[12:]\n",
    "    if c.startswith('Food-101'):\n",
    "        c = c[9:]\n",
    "    c = 'a photo of ' + c\n",
    "    new_classes.append(c)\n",
    "print(len(new_classes),\"中图片\")\n",
    "text = clip.tokenize(new_classes)\n",
    "print(text.shape)\n",
    "text_features = model.encode_text(text)\n",
    "print(\"norm前的shape\",text_features.shape)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "print(text_features.shape)\n",
    "print(\"标签处理成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[374,512,]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片加载并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data loading\n",
    "imgs_dir = '../data'\n",
    "train_labels = open('../data/train.txt').read().splitlines()\n",
    "train_imgs = [l.split(' ')[0] for l in train_labels]#对应的图片path\n",
    "train_labels = [jt.float32([int(l.split(' ')[1])]) for l in train_labels]#对应的种类序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个类挑四张图，根据train_labels中的label来挑选\n",
    "#挑选每种的前四张,生成两个对应的列表,分别存储path和类别信息\n",
    "cnt = {}\n",
    "new_train_imgs = []\n",
    "new_train_labels = []\n",
    "for i in range(len(train_imgs)):\n",
    "    label = int(train_labels[i].numpy())\n",
    "    if label not in cnt:\n",
    "        cnt[label] = 0\n",
    "    if cnt[label] < 4:\n",
    "        new_train_imgs.append(train_imgs[i])\n",
    "        new_train_labels.append(train_labels[i])\n",
    "        cnt[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate image features of training data\n",
    "train_features = []\n",
    "print('Training data processing:')\n",
    "with jt.no_grad():\n",
    "    for img in tqdm(new_train_imgs):\n",
    "        img = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        # print(\"能成功运行?\",\"image_features的shape是\",image_features.shape)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        train_features.append(image_features)\n",
    "\n",
    "train_features = jt.cat(train_features).numpy()#(1496, 512)\n",
    "train_labels = jt.cat(new_train_labels).numpy()#(1496,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "classifier = LogisticRegression(random_state=0,\n",
    "                                C=8.960,\n",
    "                                max_iter=1000,\n",
    "                                verbose=1)\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛要提交的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing dataset loading\n",
    "split = 'TestSet' + args.split\n",
    "imgs_dir = '../data/' + split\n",
    "test_imgs = os.listdir(imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "print('Testing data processing:')\n",
    "test_features = []\n",
    "with jt.no_grad():\n",
    "    for img in tqdm(test_imgs):\n",
    "        img_path = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        test_features.append(image_features)\n",
    "\n",
    "test_features = jt.cat(test_features).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "with open('result_ft.txt', 'w') as save_file:\n",
    "    i = 0\n",
    "    predictions = classifier.predict_proba(test_features)\n",
    "    for prediction in predictions.tolist():\n",
    "        prediction = np.asarray(prediction)\n",
    "        top5_idx = prediction.argsort()[-1:-6:-1]\n",
    "        save_file.write(test_imgs[i] + ' ' +\n",
    "                        ' '.join(str(idx) for idx in top5_idx) + '\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
