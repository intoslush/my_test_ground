{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ftfy regex tqdm\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from PIL import Image\n",
    "import jclip as clip\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import random\n",
    "# from colorama import Fore, Back, Style, init\n",
    "# init()\n",
    "\n",
    "jt.flags.use_cuda = 1\n",
    "print(\"包导入成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--split', type=str, default='A')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "model, preprocess = clip.load(\"ViT-B-32.pkl\")\n",
    "classes = open('../data/classname.txt').read().splitlines()#这是一个包含所有类的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别文本编码,变成一句话,然后别转为向量\n",
    "### 提示词可以尝试优化\n",
    "text_features的shape为[374,512,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode这块后面可以强化下\n",
    "text_features=0\n",
    "new_classes = []\n",
    "for c in classes:\n",
    "    c = c.split(' ')[0]\n",
    "    if c.startswith('Animal'):\n",
    "        c = c[7:]\n",
    "    if c.startswith('Thu-dog'):\n",
    "        c = c[8:]\n",
    "    if c.startswith('Caltech-101'):\n",
    "        c = c[12:]\n",
    "    if c.startswith('Food-101'):\n",
    "        c = c[9:]\n",
    "    c = 'a photo of ' + c\n",
    "    new_classes.append(c)\n",
    "print(len(new_classes),\"中图片\")\n",
    "text = clip.tokenize(new_classes)\n",
    "print(text.shape)\n",
    "text_features = model.encode_text(text)\n",
    "print(\"norm前的shape\",text_features.shape)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "print(text_features.shape)\n",
    "print(\"标签处理成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片加载并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data loading\n",
    "imgs_dir = '../data'\n",
    "train_labels = open('../data/train.txt').read().splitlines()\n",
    "train_imgs = [l.split(' ')[0] for l in train_labels]#对应的图片path\n",
    "train_labels = [jt.float32([int(l.split(' ')[1])]) for l in train_labels]#对应的种类序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个类挑四张图，根据train_labels中的label来挑选\n",
    "#挑选每种的前四张,生成两个对应的列表,分别存储path和类别信息\n",
    "cnt = {}\n",
    "new_train_imgs = []\n",
    "new_train_labels = []\n",
    "for i in range(len(train_imgs)):\n",
    "    label = int(train_labels[i].numpy())\n",
    "    if label not in cnt:\n",
    "        cnt[label] = 0\n",
    "    if cnt[label] < 4:\n",
    "        new_train_imgs.append(train_imgs[i])\n",
    "        new_train_labels.append(train_labels[i])\n",
    "        cnt[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate image features of training data\n",
    "train_features = []\n",
    "print('Training data processing:')\n",
    "with jt.no_grad():\n",
    "    for img in tqdm(new_train_imgs):\n",
    "        img = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        # print(\"能成功运行?\",\"image_features的shape是\",image_features.shape)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        train_features.append(image_features)\n",
    "\n",
    "train_features = jt.cat(train_features).numpy()#(1496, 512)\n",
    "train_labels = jt.cat(new_train_labels).numpy()#(1496,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "classifier = LogisticRegression(random_state=0,\n",
    "                                C=8.960,\n",
    "                                max_iter=1000,\n",
    "                                verbose=1)\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛要提交的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing dataset loading\n",
    "split = 'TestSet' + args.split\n",
    "imgs_dir = '../data/' + split\n",
    "test_imgs = os.listdir(imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "print('Testing data processing:')\n",
    "test_features = []\n",
    "with jt.no_grad():\n",
    "    for img in tqdm(test_imgs):\n",
    "        img_path = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        test_features.append(image_features)\n",
    "\n",
    "test_features = jt.cat(test_features).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "with open('result_ft.txt', 'w') as save_file:\n",
    "    i = 0\n",
    "    predictions = classifier.predict_proba(test_features)\n",
    "    for prediction in predictions.tolist():\n",
    "        prediction = np.asarray(prediction)\n",
    "        top5_idx = prediction.argsort()[-1:-6:-1]\n",
    "        save_file.write(test_imgs[i] + ' ' +\n",
    "                        ' '.join(str(idx) for idx in top5_idx) + '\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
