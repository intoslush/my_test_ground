{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from PIL import Image\n",
    "import jclip as clip\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "jt.flags.use_cuda = 1\n",
    "print(\"包导入成功\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--split', type=str, default='A')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "model, preprocess = clip.load(\"../data/ViT-B-32.pkl\")\n",
    "imgs_dir = '../data'\n",
    "\n",
    "def encode_pre_word(c) -> str:\n",
    "    \"\"\"更具输入的名字返回一句话\"\"\"\n",
    "    seq = 'a photo of ' + c\n",
    "    return seq\n",
    "\n",
    "def ret_class_name_dic() -> dict:\n",
    "    \"\"\"返回数字映射到动物名字的字典\"\"\"\n",
    "    classes = open('../data/classname.txt').read().splitlines() # 这是一个包含所有类的列表\n",
    "    class_name_dic = {} # 这是数字映射到动物名字的字典\n",
    "    for i in classes:\n",
    "        name, idx = i.split(' ')\n",
    "        if idx not in class_name_dic:\n",
    "            class_name_dic[idx] = name\n",
    "    return class_name_dic\n",
    "\n",
    "def train_data() -> list:\n",
    "    \"\"\"返回元素为玩意的列表['TrainSet/Animal/Bee/57.jpg', '1'] 每类四个的打乱列表\"\"\"\n",
    "    train_labels = open('../data/train.txt').read().splitlines()\n",
    "    train_data_dic = {} # 每类的图片的字典\n",
    "    for i in train_labels:\n",
    "        path, class_name = i.split(' ')\n",
    "        if class_name in train_data_dic:\n",
    "            train_data_dic[class_name].append([path, class_name])\n",
    "        else:\n",
    "            train_data_dic[class_name] = [[path, class_name]]\n",
    "    # 训练集的要训练的每类四张的列表\n",
    "    ret_list = [] # 用于返回每类四张的列表\n",
    "    for i in train_data_dic:\n",
    "        ret_list += random.sample(train_data_dic[i], 4)\n",
    "    random.shuffle(ret_list)\n",
    "    return ret_list # 内存不够再优化\n",
    "\n",
    "def test_data(train_data: list) -> list:\n",
    "    \"\"\"返回元素为玩意的列表['TrainSet/Animal/Bee/57.jpg 1] 共计3000个用于测试\n",
    "    同时剔除训练集中的元素\"\"\"\n",
    "    set1 = set(map(tuple, train_data))\n",
    "    train_labels = open('../data/train.txt').read().splitlines()\n",
    "    result = [item for item in train_labels if tuple(item.split(' ')) not in set1] \n",
    "    return random.sample(result, 3000)\n",
    "\n",
    "train_img_features = []\n",
    "train_word_features = []\n",
    "count = 0\n",
    "class_name_dic = ret_class_name_dic()\n",
    "\n",
    "with jt.no_grad():\n",
    "    for info in tqdm(train_data()):\n",
    "        img, indx = info\n",
    "        img = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        train_img_features.append(image_features)\n",
    "\n",
    "        a_seq = encode_pre_word(class_name_dic[indx]) # 转为句子\n",
    "        token = clip.tokenize(a_seq)\n",
    "        text_features = model.encode_text(token)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        train_word_features.append(text_features)\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "\n",
    "train_img_features = jt.concat(train_img_features, dim=0)\n",
    "train_word_features = jt.concat(train_word_features, dim=0)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 解冻视觉模型最后两个残差块的参数\n",
    "for param in model.visual.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.visual.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻文本模型最后两个残差块的参数\n",
    "for param in model.transformer.resblocks[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.transformer.resblocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻 ln_final 层的参数\n",
    "for param in model.ln_final.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "def score_function(image_embedding, text_embedding):\n",
    "    # 使用余弦相似度作为评分函数\n",
    "    return jt.matmul(image_embedding, text_embedding.transpose(1, 0))\n",
    "\n",
    "# 定义 CLIP 损失函数\n",
    "def clip_loss(image_embeddings, text_embeddings, temperature=1.0):\n",
    "    batch_size = image_embeddings.shape[0]\n",
    "    \n",
    "    # 计算图像和文本之间的相似度得分\n",
    "    logits_per_image = score_function(image_embeddings, text_embeddings) / temperature\n",
    "    logits_per_text = logits_per_image.transpose(1, 0)\n",
    "    \n",
    "    # 创建标签\n",
    "    ground_truth = jt.arange(batch_size, dtype=jt.int64)\n",
    "    \n",
    "    # 计算交叉熵损失\n",
    "    loss_img = jt.nn.cross_entropy_loss(logits_per_image, ground_truth)\n",
    "    loss_text = jt.nn.cross_entropy_loss(logits_per_text, ground_truth)\n",
    "    \n",
    "    return (loss_img + loss_text) / 2\n",
    "\n",
    "# 将 filter 生成器转换为列表\n",
    "params_to_optimize = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = jt.optim.AdamW(params_to_optimize, lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "num_batches = len(train_img_features) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_img_features = train_img_features[i * batch_size: (i + 1) * batch_size]\n",
    "        batch_text_features = train_word_features[i * batch_size: (i + 1) * batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        image_features = model.encode_image(batch_img_features)\n",
    "        text_features = model.encode_text(batch_text_features)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = clip_loss(image_features, text_features)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/num_batches:.4f}\")\n",
    "\n",
    "print(\"微调训练完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = open('../data/classname.txt').read().splitlines()\n",
    "\n",
    "# remove the prefix Animal, Thu-dog, Caltech-101, Food-101\n",
    "\n",
    "new_classes = []\n",
    "for c in classes:\n",
    "    c = c.split(' ')[0]\n",
    "    if c.startswith('Animal'):\n",
    "        c = c[7:]\n",
    "    if c.startswith('Thu-dog'):\n",
    "        c = c[8:]\n",
    "    if c.startswith('Caltech-101'):\n",
    "        c = c[12:]\n",
    "    if c.startswith('Food-101'):\n",
    "        c = c[9:]\n",
    "    c = 'a photo of ' + c\n",
    "    new_classes.append(c)\n",
    "\n",
    "text = clip.tokenize(new_classes)\n",
    "text_features = model.encode_text(text)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'TestSetA' \n",
    "\n",
    "imgs_dir = '../data/' + split\n",
    "imgs = os.listdir(imgs_dir)\n",
    "\n",
    "save_file = open('result.txt', 'w')\n",
    "\n",
    "preds = []\n",
    "with jt.no_grad():\n",
    "    for img in tqdm(imgs):\n",
    "        img_path = os.path.join(imgs_dir, img)\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_probs = (100.0 *\n",
    "                      image_features @ text_features.transpose(0, 1)).softmax(\n",
    "                          dim=-1)\n",
    "        # top5 predictions\n",
    "        _, top_labels = text_probs[0].topk(5)\n",
    "        preds.append(top_labels)\n",
    "        # save top5 predictions to file\n",
    "        save_file.write(img + ' ' +\n",
    "                        ' '.join([str(p.item()) for p in top_labels]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas=test_data()\n",
    "with jt.no_grad():\n",
    "    count_ac=0\n",
    "    total=0\n",
    "    for info in tqdm(test_datas):\n",
    "        img_path,class_name = info\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_probs = (100.0 *\n",
    "                      image_features @ text_features.transpose(0, 1)).softmax(\n",
    "                          dim=-1)\n",
    "        # top5 predictions\n",
    "        _, top_labels = text_probs[0].topk(1)\n",
    "        preds.append(top_labels)\n",
    "        # save top5 predictions to file\n",
    "        save_file.write(img + ' ' +\n",
    "                        ' '.join([str(p.item()) for p in top_labels]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
